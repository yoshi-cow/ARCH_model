{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1904a70-8c26-4c90-b6a1-371f2406c6c9",
   "metadata": {},
   "source": [
    "# GARCHコードサンプル\n",
    "\n",
    "結論から言うと、\n",
    "\n",
    "* コードの流れと GARCH(1,1) の使い方としては「ほぼ正しい」です\n",
    "* ただし **説明コメントの一部（`alpha[2]`, `beta[2]`）が間違い** になっているのと、\n",
    "* 予測ボラティリティのプロットの軸・日付周りを少し整えると、教材としてかなりきれいになります\n",
    "\n",
    "なので、\n",
    "\n",
    "1. 修正版の「完成コード」\n",
    "2. そのコードのパートごとの詳しい解説\n",
    "   を順に書きます。\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 修正版フルコード（コメント付き）\n",
    "\n",
    "```python\n",
    "# ===========================\n",
    "# 0. 必要なライブラリのインストール（初回のみ）\n",
    "# ===========================\n",
    "# !pip install arch yfinance\n",
    "\n",
    "# ===========================\n",
    "# 1. ライブラリのインポート\n",
    "# ===========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from pandas.tseries.offsets import BDay  # 予測ボラティリティ用の日付生成に使用\n",
    "\n",
    "# ===========================\n",
    "# 2. データ取得 & 日次リターンの計算\n",
    "# ===========================\n",
    "# S&P 500 (^GSPC) の日次データを取得\n",
    "data = yf.download('^GSPC', start='2010-01-01', end='2023-12-31')\n",
    "\n",
    "# 調整終値のパーセンテージ変化（リターン）を計算\n",
    "# 通常 pct_change() は 0.01 = 1% のような「小さい値」になります。\n",
    "# GARCH 推定では、最適化を安定させるために 100倍して「%単位」にするのが\n",
    "# 実務でもよく推奨されています（例: 0.5% → 0.5）:contentReference[oaicite:0]{index=0}\n",
    "returns = 100 * data['Adj Close'].pct_change().dropna()\n",
    "returns.name = 'sp500_returns'\n",
    "\n",
    "# ===========================\n",
    "# 3. リターン系列の可視化（ボラティリティ・クラスタリングの確認）\n",
    "# ===========================\n",
    "plt.figure(figsize=(12, 6))\n",
    "returns.plot(title='S&P 500 Daily Returns (in %)')\n",
    "plt.ylabel('Daily Return (%)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ===========================\n",
    "# 4. GARCH(1,1) モデルの指定と推定\n",
    "# ===========================\n",
    "# arch_model の主な引数:\n",
    "# - mean='Constant' : r_t = μ + ε_t という「定数平均」モデル\n",
    "# - vol='Garch'     : 分散方程式に GARCH(p, q) を使う （大小文字は 'Garch' でOK）:contentReference[oaicite:1]{index=1}\n",
    "# - p=1, q=1        : GARCH(1,1) モデル\n",
    "# - dist='Normal'   : 残差 z_t ~ N(0,1) を仮定\n",
    "am = arch_model(\n",
    "    returns,\n",
    "    mean='Constant',\n",
    "    vol='Garch',\n",
    "    p=1,\n",
    "    q=1,\n",
    "    dist='Normal'\n",
    ")\n",
    "\n",
    "# モデルの推定\n",
    "# update_freq=5 : 5イテレーションごとに推定の進捗を表示\n",
    "result = am.fit(update_freq=5)\n",
    "\n",
    "# 推定結果のサマリーを表示\n",
    "print(result.summary())\n",
    "\n",
    "# ===========================\n",
    "# 5. 係数の解釈メモ（説明用）\n",
    "# ===========================\n",
    "\"\"\"\n",
    "係数の典型的な読み方（例）:\n",
    "  mu         : 平均リターン μ\n",
    "  omega      : 分散方程式の定数項 ω\n",
    "  alpha[1]   : 直近のショック ε_{t-1}^2 が分散に与える影響（ARCH 項）\n",
    "  beta[1]    : 直近の分散 σ_{t-1}^2 が分散に与える影響（GARCH 項）\n",
    "\n",
    "もし alpha[1] = 0.10, beta[1] = 0.88 と推定された場合:\n",
    "  ・持続性: α_1 + β_1 = 0.98 となり、1に非常に近い\n",
    "      → 一度大きなショックが起きると、その影響が長く残り、\n",
    "        ボラティリティの高い状態がしばらく続くことを意味する\n",
    "  ・有意性: alpha[1], beta[1] の P>|z| がどちらも 0.05 より十分小さいか確認\n",
    "      → 小さいほど「この係数は 0 ではない」と統計的に言える\n",
    "      → もし p値が大きい（例: 0.3）なら、その係数は統計的に有意でない\n",
    "       （＝そのラグは効いていない可能性があり、次数やモデルの見直し候補）\n",
    "\"\"\"\n",
    "\n",
    "# ===========================\n",
    "# 6. モデル診断：標準化残差と Ljung-Box 検定\n",
    "# ===========================\n",
    "# 標準化残差: \\tilde{ε}_t = ε_t / σ_t\n",
    "std_resid = result.std_resid.dropna()\n",
    "\n",
    "print(\"\\n--- GARCH Model Diagnostics ---\")\n",
    "\n",
    "# (1) 標準化残差そのものの Ljung-Box 検定\n",
    "#     → 平均モデル（ここでは定数 + GARCH）の残差に自己相関が残っていないか？\n",
    "lb_test_resid = acorr_ljungbox(std_resid, lags=[1, 5, 10], return_df=True)\n",
    "print(\"\\nLjung-Box test on Standardized Residuals:\")\n",
    "print(lb_test_resid)\n",
    "print(\"※ lb_pvalue がすべて 0.05 より大きいことが望ましい（自己相関なし）\")\n",
    "\n",
    "# (2) 標準化残差の2乗の Ljung-Box 検定\n",
    "#     → 条件付き分散モデル（GARCH）が ARCH 効果を取り切れているか？\n",
    "lb_test_sq_resid = acorr_ljungbox(std_resid**2, lags=[1, 5, 10], return_df=True)\n",
    "print(\"\\nLjung-Box test on Squared Standardized Residuals:\")\n",
    "print(lb_test_sq_resid)\n",
    "print(\"※ lb_pvalue がすべて 0.05 より大きいことが望ましい（残りの ARCH 効果なし）\")\n",
    "\n",
    "\"\"\"\n",
    "診断のざっくりした読み方:\n",
    "  - (1) 標準化残差の Ljung-Box 検定で p値が小さい:\n",
    "       → 平均モデル（mean='Constant'）が不十分で、まだ予測可能なパターンが残っている可能性\n",
    "         mean='AR' など AR-GARCH モデルを検討\n",
    "  - (2) 標準化残差^2 の Ljung-Box 検定で p値が小さい:\n",
    "       → GARCH(1,1) でもボラティリティクラスタリングを取り切れていない\n",
    "         → GARCH(1,2), GARCH(2,1) や EGARCH, GJR-GARCH などの拡張を検討\n",
    "  - 両方とも十分大きな p値:\n",
    "       → この GARCH(1,1) は「指定としては大きな問題はなさそう」と判断でき、\n",
    "         ボラティリティ予測に進んでよい\n",
    "\"\"\"\n",
    "\n",
    "# ===========================\n",
    "# 7. 将来 5日間のボラティリティ予測\n",
    "# ===========================\n",
    "# horizon=5 で 5ステップ先までの条件付き分散 σ_t^2 を予測\n",
    "forecasts = result.forecast(horizon=5)\n",
    "\n",
    "# forecasts.variance は DataFrame:\n",
    "#   行: 過去データの日付\n",
    "#   列: 予測ホライズン (h.1, h.2, ..., h.5)\n",
    "# 最後の行 (iloc[-1]) が「サンプルの最終日から見た」将来5日分の予測分散\n",
    "predicted_variance = forecasts.variance.iloc[-1]\n",
    "print(\"\\n--- Predicted Variance (5 days ahead) ---\")\n",
    "print(predicted_variance)\n",
    "\n",
    "# 分散の平方根をとって「標準偏差（ボラティリティ）」に変換\n",
    "predicted_volatility = np.sqrt(predicted_variance)\n",
    "\n",
    "print(\"\\n--- Predicted Volatility (Std. Dev. in %) ---\")\n",
    "print(predicted_volatility)\n",
    "print(\"※ リターンを 100 倍しているので、これは『日次リターンの%ボラティリティ』です。\")\n",
    "\n",
    "# ===========================\n",
    "# 8. 過去のフィットされたボラティリティと将来予測の可視化\n",
    "# ===========================\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 過去の条件付きボラティリティ（σ_t）\n",
    "plt.plot(\n",
    "    result.conditional_volatility,\n",
    "    label='Fitted GARCH(1,1) Volatility'\n",
    ")\n",
    "\n",
    "# 予測ボラティリティ用に「将来の日付インデックス」を作る\n",
    "last_date = returns.index[-1]\n",
    "future_index = [last_date + BDay(i) for i in range(1, len(predicted_volatility) + 1)]\n",
    "predicted_volatility.index = future_index\n",
    "\n",
    "# 将来の予測ボラティリティ\n",
    "plt.plot(\n",
    "    predicted_volatility,\n",
    "    'r--',\n",
    "    label='Forecasted Volatility (Next 5 Business Days)'\n",
    ")\n",
    "\n",
    "plt.title('GARCH(1,1) Fitted and Forecasted Volatility (S&P 500)')\n",
    "plt.ylabel('Volatility (Std. Dev. in %)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. どこが「間違い／改善ポイント」だったか\n",
    "\n",
    "### (1) `alpha[2]`, `beta[2]` の説明\n",
    "\n",
    "元コードのコメント：\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "もし alpha[2] が 0.1、beta[2] が 0.88 と推定された場合：\n",
    "...\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "* GARCH(1,1) では **αのラグは1つだけ** なので、`alpha[1]`, `beta[1]` が正しいです\n",
    "* `result.summary()` を出してみると、実際に列名は `alpha[1]`, `beta[1]` になっています ([Qiita][1])\n",
    "\n",
    "→ ここだけ **添字を 1 に修正** しました。\n",
    "\n",
    "---\n",
    "\n",
    "### (2) Ljung-Box 検定のラグ\n",
    "\n",
    "元コードでは：\n",
    "\n",
    "```python\n",
    "lb_test_resid = acorr_ljungbox(std_resid, lags=[1], return_df=True)\n",
    "...\n",
    "lb_test_sq_resid = acorr_ljungbox(std_resid**2, lags=[1], return_df=True)\n",
    "```\n",
    "\n",
    "でも良いのですが、教材としては\n",
    "\n",
    "* ラグ1だけでなく、**1, 5, 10 など複数のラグ**で p値を見た方が、\n",
    "  「どのタイムスケールで自己相関が残っているか」が見えてわかりやすいです。([Read the Docs][2])\n",
    "\n",
    "→ `lags=[1, 5, 10]` に変更しました（もちろん、実務では 10, 20 など好きに変えてOK）。\n",
    "\n",
    "---\n",
    "\n",
    "### (3) ボラティリティ予測のプロットの横軸\n",
    "\n",
    "元コードでは：\n",
    "\n",
    "```python\n",
    "plt.plot(result.conditional_volatility, label='Fitted ...')\n",
    "plt.plot(predicted_volatility, 'r--', label='Forecasted ...')\n",
    "```\n",
    "\n",
    "* `result.conditional_volatility` は「過去日付の index」を持った Series\n",
    "* `predicted_volatility` は「h.1, h.2, ...」の index（将来日付ではない）\n",
    "\n",
    "になっており、**横軸のスケールが混ざっている**状態になります。\n",
    "\n",
    "→ 修正版では、`pandas.tseries.offsets.BDay` を使い、\n",
    "\n",
    "* 「最後の日付 + 1営業日, ... + 5営業日」の index を作って\n",
    "* `predicted_volatility.index = future_index` としてからプロット\n",
    "\n",
    "するようにしました。これで、グラフの横軸が「日付として自然な連続」になります。\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 各ステップの「GARCH 的な意味」\n",
    "\n",
    "最後に、GARCH モデルを「どう使うか」という視点で、コードの流れをまとめます。\n",
    "\n",
    "### ① リターンを作って 100 倍する理由\n",
    "\n",
    "```python\n",
    "returns = 100 * data['Adj Close'].pct_change().dropna()\n",
    "```\n",
    "\n",
    "* GARCH は「**リターンの条件付き分散**」をモデル化するので、\n",
    "  **価格ではなくリターン**（%変化）の系列を使います。\n",
    "* arch のドキュメントでも、`returns = 100 * price.pct_change()` のような形が推奨されています。([arch.readthedocs.io][3])\n",
    "\n",
    "  * スケールが小さすぎると最適化が不安定になりやすい\n",
    "  * 100倍して「%単位」にすると、他のパラメータとスケールが揃って推定が安定\n",
    "\n",
    "### ② `arch_model` で GARCH(1,1) を指定\n",
    "\n",
    "```python\n",
    "am = arch_model(\n",
    "    returns,\n",
    "    mean='Constant',\n",
    "    vol='Garch',\n",
    "    p=1,\n",
    "    q=1,\n",
    "    dist='Normal'\n",
    ")\n",
    "```\n",
    "\n",
    "* **平均方程式**:\n",
    "  $( r_t = \\mu + \\epsilon_t )$\n",
    "\n",
    "* **分散方程式（GARCH(1,1)）**: ([ウィキペディア][4])\n",
    "\n",
    "$$\n",
    "  \\sigma_t^2 = \\omega + \\alpha_1 \\epsilon_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2\n",
    "$$\n",
    "\n",
    "* これで、「直近のショック（ε²）」と「直近の分散」が、\n",
    "  どれくらい次の分散に効いているか（α, β）を推定できます。\n",
    "\n",
    "### ③ サマリーで何を見るか\n",
    "\n",
    "`result.summary()` を見ると、主にチェックしたいのは：\n",
    "\n",
    "* `mu`：平均リターン（金融では 0 に近いことも多い）\n",
    "* `omega`：平常時の「ベース」分散レベル\n",
    "* `alpha[1]`：ショックへの即時反応\n",
    "* `beta[1]`：ボラティリティの持続性\n",
    "* `alpha[1] + beta[1]` が 1 に近い → ショックの影響が長く残る（金融データではよくある）([mingze-gao.com][5])\n",
    "* 各係数の **p値が十分小さいか** → その係数が統計的に意味があるか\n",
    "\n",
    "### ④ Ljung-Box 2種類の検定の意味\n",
    "\n",
    "1. **標準化残差そのもの**\n",
    "\n",
    "   * 目的：平均モデル（ここでは定数 + GARCH）が十分か？\n",
    "   * p値が小さい→まだ自己相関が残っている → AR を入れるなどを検討\n",
    "\n",
    "2. **標準化残差の2乗**\n",
    "\n",
    "   * 目的：分散モデル（GARCH）が ARCH 効果を取り切れているか？\n",
    "   * ここで p値が小さい→GARCH(1,1) でもボラティリティのパターンを捉え切れていない\n",
    "     → 次数アップや EGARCH / GJR-GARCH などを検討\n",
    "\n",
    "この 2つを見ることで、\n",
    "\n",
    "* **平均のモデリング**\n",
    "* **分散のモデリング**\n",
    "\n",
    "がそれぞれ十分かどうかを切り分けて考えられます。\n",
    "\n",
    "### ⑤ 予測ボラティリティの解釈\n",
    "\n",
    "```python\n",
    "forecasts = result.forecast(horizon=5)\n",
    "predicted_variance = forecasts.variance.iloc[-1]\n",
    "predicted_volatility = np.sqrt(predicted_variance)\n",
    "```\n",
    "\n",
    "* `predicted_volatility` は「次の1日〜5日」の\n",
    "  **予測ボラティリティ（標準偏差, %単位）** です。\n",
    "* 例えば `h.1` が 1.2 なら、翌日の 1標準偏差レンジは\n",
    "  「±1.2%」程度と解釈できます（※リターンを 100倍しているため）。\n",
    "\n",
    "これを過去の `result.conditional_volatility` と一緒にプロットすると、\n",
    "\n",
    "* 過去：実際のデータに対して GARCH がどのようにボラティリティを推定したか\n",
    "* 将来：それを元に、近い将来のボラティリティをどう予測しているか\n",
    "\n",
    "が視覚的に理解しやすくなります。\n",
    "\n",
    "---\n",
    "\n",
    "もし良ければ、次のステップとして：\n",
    "\n",
    "* **mean='AR'** に変えて AR-GARCH にしてみる\n",
    "* dist を `'StudentsT'` に変えて「ファットテール対応 GARCH」を試す\n",
    "\n",
    "などを一緒にやってみましょう。「平均モデル」「分散モデル」「誤差分布」を組み合わせていくと、GARCH 系の理解が一気に深まります。\n",
    "\n",
    "[1]: https://qiita.com/maskot1977/items/ce60b82ff51feaf5f8f0?utm_source=chatgpt.com \"ChatGPTとPythonで学ぶ GARCH #arch\"\n",
    "[2]: https://media.readthedocs.org/pdf/arch/stable/arch.pdf?utm_source=chatgpt.com \"arch Documentation\"\n",
    "[3]: https://arch.readthedocs.io/en/stable/univariate/introduction.html?utm_source=chatgpt.com \"Introduction to ARCH Models - arch 7.2.0\"\n",
    "[4]: https://en.wikipedia.org/wiki/Autoregressive_conditional_heteroskedasticity?utm_source=chatgpt.com \"Autoregressive conditional heteroskedasticity\"\n",
    "[5]: https://mingze-gao.com/posts/garch-estimation/?utm_source=chatgpt.com \"GARCH Estimation\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52a6ef-2e79-45a6-9b7c-1333bcb0a461",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# mean=\"AR\"に換えた場合について\n",
    "\n",
    "いいですね、ここで一気に「AR-GARCH」を押さえておくと、だいぶ実務寄りになります。\n",
    "\n",
    "### 1. mean=\"Constant\" と mean=\"AR\" の違い\n",
    "\n",
    "元コード（mean='Constant'）では、リターン (r_t) のモデルは\n",
    "\n",
    "$$\n",
    "r_t = \\mu + \\epsilon_t\n",
    "$$\n",
    "\n",
    "だけでした。\n",
    "これを **mean='AR'** にすると、平均の部分が **自己回帰（AR）** になります：\n",
    "\n",
    "$$\n",
    "r_t = \\mu + \\varphi_1 r_{t-1} + \\varphi_2 r_{t-2} + \\cdots + \\epsilon_t\n",
    "$$\n",
    "\n",
    "ARCH/GARCH 部分（分散のモデル）はそのままなので、\n",
    "\n",
    "$$\n",
    "\\sigma_t^2 = \\omega + \\alpha_1 \\epsilon_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2\n",
    "$$\n",
    "\n",
    "と組み合わせると、**AR(p)–GARCH(1,1)** モデルになります。\n",
    "`arch_model` では、\n",
    "\n",
    "* `mean='AR'`\n",
    "* `lags=1` なら AR(1)\n",
    "* `lags=2` なら AR(2)\n",
    "* `lags=[1,3]` のようにリストで「使いたいラグだけ指定」も可能\n",
    "\n",
    "という指定方法になっています。\n",
    "\n",
    "---\n",
    "\n",
    "### 2. コードを mean=\"AR\" に変える例\n",
    "\n",
    "元のコードの GARCH 部分だけ差し替えると、こうなります。\n",
    "\n",
    "```python\n",
    "from arch import arch_model\n",
    "\n",
    "# --- AR(1)-GARCH(1,1) モデルの指定 ---\n",
    "# mean='AR' : 平均モデルを自己回帰(AR)にする\n",
    "# lags=1    : AR(1)（1期前のリターンを使う）\n",
    "am = arch_model(\n",
    "    returns,\n",
    "    mean='AR',\n",
    "    lags=1,          # ★ここが追加\n",
    "    vol='Garch',\n",
    "    p=1, q=1,\n",
    "    dist='Normal'\n",
    ")\n",
    "\n",
    "result = am.fit(update_freq=5)\n",
    "print(result.summary())\n",
    "```\n",
    "\n",
    "このようにすると、サマリーには\n",
    "\n",
    "* Mean Model のところに\n",
    "\n",
    "  * `Const`（定数 μ）\n",
    "  * `sp500_returns[1]` などの **AR係数**\n",
    "* Volatility Model はこれまで通り\n",
    "\n",
    "  * `omega`, `alpha[1]`, `beta[1]`\n",
    "\n",
    "が並びます。\n",
    "\n",
    "---\n",
    "\n",
    "### 3. 何がうれしいのか（いつ mean='AR' を使うか）\n",
    "\n",
    "**直感的な役割分担**はこうです：\n",
    "\n",
    "* **平均モデル（mean='Constant' or 'AR'）**\n",
    "  → リターンの「予測可能な成分」を捉える\n",
    "* **分散モデル（GARCH）**\n",
    "  → 「予測できないショックの大きさの自己相関（ボラティリティクラスタリング）」を捉える\n",
    "\n",
    "もし mean='Constant' の状態で、\n",
    "\n",
    "* 標準化残差 `std_resid` に Ljung-Box 検定をかけたとき **p値が小さい** → 残差に自己相関が残っている\n",
    "\n",
    "  * ⇒ 「平均のモデリングが足りていない」サイン\n",
    "  * ⇒ mean='AR', lags=1（または 2）などで **AR成分を入れてあげる**\n",
    "\n",
    "と考えます。\n",
    "\n",
    "逆に、\n",
    "\n",
    "* mean='Constant' のままでも `std_resid` の Ljung-Box の p値が十分大きい\n",
    "  → そもそもリターンにほぼ自己相関がない\n",
    "  → 無理に mean='AR' にしなくてもよい（むしろベタな金融データではけっこうよくある）\n",
    "\n",
    "というケースも多いです。\n",
    "\n",
    "---\n",
    "\n",
    "### 4. AR(1)-GARCH(1,1) の数式イメージ\n",
    "\n",
    "`mean='AR', lags=1` の場合、モデルは：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "r_t &= \\mu + \\varphi_1 r_{t-1} + \\epsilon_t, \\\n",
    "\\epsilon_t &= \\sigma_t z_t,\\quad z_t \\sim \\mathcal{N}(0,1), \\\n",
    "\\sigma_t^2 &= \\omega + \\alpha_1 \\epsilon_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* $(\\varphi_1)$ が **0 に近い** → 過去リターンからの予測力はほとんどない（効率的市場っぽい）\n",
    "* $(\\varphi_1)$ が **正で有意** → 「前日上がると、今日も少し上がりやすい」みたいなモメンタム\n",
    "* $(\\varphi_1)$ が **負で有意** → 「前日の動きが反転しやすい」ようなリバーサル\n",
    "\n",
    "推定後は、`result.summary()` の Mean Model の行で\n",
    "\n",
    "* `sp500_returns[1]` の `coef`（$= (\\varphi_1)$）\n",
    "* その `P>|t|`（p値）\n",
    "\n",
    "を見て、「AR を入れる価値があったか」を確認します。\n",
    "\n",
    "---\n",
    "\n",
    "### 5. mean='AR' にしたときの診断の読み方\n",
    "\n",
    "`std_resid` / `std_resid**2` に対する Ljung-Box は、AR-GARCH にしても同じように使えます。\n",
    "\n",
    "1. **標準化残差 (`std_resid`) の Ljung-Box**\n",
    "\n",
    "   * 目的：AR を入れたことで「平均のパターン」が取り切れているか？\n",
    "   * AR を入れる前より p値が上がり、0.05を超えるようなら\n",
    "     →「平均モデルが改善した」と判断しやすいです。\n",
    "\n",
    "2. **標準化残差の二乗 (`std_resid**2`) の Ljung-Box**\n",
    "\n",
    "   * 目的：GARCH 部分でボラティリティクラスタリングを取り切れているか？\n",
    "   * ここは mean='Constant' のときと同じ読み方\n",
    "     → p値が小さければ GARCH 次数やモデルの見直し。\n",
    "\n",
    "---\n",
    "\n",
    "### 6. lags をどう選ぶか？\n",
    "\n",
    "実務的には、だいたい次のように決めます：\n",
    "\n",
    "1. **ACF・PACF をざっと見る**\n",
    "\n",
    "   * returns の ACF/PACF プロットを描いて、\n",
    "\n",
    "     * ラグ1だけ大きい → AR(1)\n",
    "     * ラグ1と2がそこそこ → AR(2)\n",
    "2. **情報量基準（AIC/BIC）を見る**\n",
    "\n",
    "   * `lags=1,2,3,...` を変えながらフィットして、AIC/BICが一番小さいものを選ぶ\n",
    "3. **経済的な直感**\n",
    "\n",
    "   * 日次株価リターン → そもそも AR がほぼゼロのことが多いので、無理に入れない\n",
    "   * 低頻度のマクロ指標など → AR が効きやすいのでもう少し高次まで試す価値あり\n",
    "\n",
    "`arch_model` の `lags` は\n",
    "**「スカラーなら 1〜lags まで全部」**\n",
    "**「リストなら指定したラグだけ」**\n",
    "という仕様です。\n",
    "\n",
    "---\n",
    "\n",
    "### 7. まとめ：mean=\"AR\" を使うときのストーリー\n",
    "\n",
    "1. まずは mean='Constant', GARCH(1,1) でフィット\n",
    "2. 標準化残差に自己相関が残っていたら\n",
    "   → mean='AR', lags=1（必要なら2,3…）で AR-GARCH に変更\n",
    "3. `result.summary()` で AR 係数の有意性を見る\n",
    "4. Ljung-Box で `std_resid` の自己相関が消えているか確認\n",
    "5. 問題なければ、その AR-GARCH モデルでボラティリティ予測へ\n",
    "\n",
    "この流れをひと通り回せるようになると、\n",
    "\n",
    "* 「平均のモデリング」と「ボラティリティのモデリング」を切り分けて考える\n",
    "* AR 部分を足した方が良いケース／いらないケースを判断できる\n",
    "\n",
    "という、より“中級者っぽい”立ち回りができるようになります。\n",
    "\n",
    "---\n",
    "\n",
    "もしよければ、次は：\n",
    "\n",
    "* `mean='AR', lags=1` と `mean='Constant'` で Ljung-Box の結果や AIC/BIC を比較する\n",
    "* ある銘柄（日次ではなく 1時間足など）で AR 部分が効いている例を一緒に見てみる\n",
    "\n",
    "…という「実データ比較」もやってみましょうか？\n",
    "\n",
    "<br>\n",
    "\n",
    "## 実データ比較\n",
    "\n",
    "いいですね、「実データで mean='Constant' と mean='AR' を比べる」までやると、一気に“使いこなしてる感”が出ます 😊\n",
    "\n",
    "ここでは **「自分のPCでそのまま回せる比較ノート」** をイメージして説明します。\n",
    "\n",
    "---\n",
    "\n",
    "## 全体の流れ\n",
    "\n",
    "1. 共通の前処理（S&P500 のリターンを作る）\n",
    "2. モデル①：mean='Constant', GARCH(1,1)\n",
    "3. モデル②：mean='AR', lags=1 の AR(1)-GARCH(1,1)\n",
    "4. AIC/BIC と Ljung-Box の結果を横並びで比較\n",
    "5. 結果をどう判断するか（何を見ればよいか）\n",
    "\n",
    "> ※ 実際の数値は、あなたの環境で実行した結果に従ってください。\n",
    "> ここでは「どういうコードを書き、何を見て、どう解釈するか」を軸に説明します。\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 共通の前処理（S&P500 日次リターン）\n",
    "\n",
    "前回とほぼ同じです。後でそのままコピペで使えるようにまとめます。\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データ取得\n",
    "data = yf.download('^GSPC', start='2010-01-01', end='2023-12-31')\n",
    "\n",
    "# 日次リターン（%単位）\n",
    "returns = 100 * data['Adj Close'].pct_change().dropna()\n",
    "returns.name = 'sp500_returns'\n",
    "\n",
    "# 確認用プロット（任意）\n",
    "returns.plot(figsize=(12, 4), title='S&P 500 Daily Returns (%)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. モデル①：mean='Constant', GARCH(1,1)\n",
    "\n",
    "まずは「基準モデル」として、前回の mean='Constant' モデルをフィットします。\n",
    "\n",
    "```python\n",
    "# ========== モデル1: Constant + GARCH(1,1) ==========\n",
    "am_const = arch_model(\n",
    "    returns,\n",
    "    mean='Constant',\n",
    "    vol='Garch',\n",
    "    p=1, q=1,\n",
    "    dist='Normal'\n",
    ")\n",
    "\n",
    "res_const = am_const.fit(update_freq=5)\n",
    "print(res_const.summary())\n",
    "```\n",
    "\n",
    "ここで見るポイントは：\n",
    "\n",
    "* `omega`, `alpha[1]`, `beta[1]` の符号と有意性 (P>|z|)\n",
    "* AIC/BIC（後で使うので取り出す）\n",
    "* Ljung-Box で残差の自己相関が残っているか\n",
    "\n",
    "診断コード：\n",
    "\n",
    "```python\n",
    "# 標準化残差\n",
    "std_resid_const = res_const.std_resid.dropna()\n",
    "\n",
    "# Ljung-Box (残差)\n",
    "lb_const_resid = acorr_ljungbox(std_resid_const, lags=[1, 5, 10], return_df=True)\n",
    "\n",
    "# Ljung-Box (残差^2)\n",
    "lb_const_sq = acorr_ljungbox(std_resid_const**2, lags=[1, 5, 10], return_df=True)\n",
    "\n",
    "print(\"=== Model 1: Constant + GARCH(1,1) ===\")\n",
    "print(\"AIC:\", res_const.aic)\n",
    "print(\"BIC:\", res_const.bic)\n",
    "print(\"\\nLjung-Box on std_resid:\")\n",
    "print(lb_const_resid)\n",
    "print(\"\\nLjung-Box on std_resid^2:\")\n",
    "print(lb_const_sq)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. モデル②：mean='AR', lags=1 → AR(1)-GARCH(1,1)\n",
    "\n",
    "次に **平均に AR(1) を入れたモデル** を同じデータで推定します。\n",
    "\n",
    "```python\n",
    "# ========== モデル2: AR(1) + GARCH(1,1) ==========\n",
    "am_ar1 = arch_model(\n",
    "    returns,\n",
    "    mean='AR',  # ★ここだけ違う\n",
    "    lags=1,     # AR(1)\n",
    "    vol='Garch',\n",
    "    p=1, q=1,\n",
    "    dist='Normal'\n",
    ")\n",
    "\n",
    "res_ar1 = am_ar1.fit(update_freq=5)\n",
    "print(res_ar1.summary())\n",
    "```\n",
    "\n",
    "平均モデルは数式的にはこうなります：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "r_t &= \\mu + \\varphi_1 r_{t-1} + \\epsilon_t, \\\n",
    "\\epsilon_t &= \\sigma_t z_t,\\quad z_t \\sim N(0,1), \\\n",
    "\\sigma_t^2 &= \\omega + \\alpha_1\\epsilon_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "サマリーで見るべきは：\n",
    "\n",
    "* Mean Model のところの `sp500_returns[1]`（これが (\\varphi_1)）\n",
    "\n",
    "  * 係数の大きさ\n",
    "  * `P>|t|` が小さいかどうか（有意かどうか）\n",
    "\n",
    "診断コードも同様に：\n",
    "\n",
    "```python\n",
    "# 標準化残差\n",
    "std_resid_ar1 = res_ar1.std_resid.dropna()\n",
    "\n",
    "# Ljung-Box (残差)\n",
    "lb_ar1_resid = acorr_ljungbox(std_resid_ar1, lags=[1, 5, 10], return_df=True)\n",
    "\n",
    "# Ljung-Box (残差^2)\n",
    "lb_ar1_sq = acorr_ljungbox(std_resid_ar1**2, lags=[1, 5, 10], return_df=True)\n",
    "\n",
    "print(\"=== Model 2: AR(1) + GARCH(1,1) ===\")\n",
    "print(\"AIC:\", res_ar1.aic)\n",
    "print(\"BIC:\", res_ar1.bic)\n",
    "print(\"\\nLjung-Box on std_resid:\")\n",
    "print(lb_ar1_resid)\n",
    "print(\"\\nLjung-Box on std_resid^2:\")\n",
    "print(lb_ar1_sq)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. 結果の「横並び比較」\n",
    "\n",
    "最後に、2モデルの指標を同じテーブルで見ると直感的です。\n",
    "\n",
    "```python\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': ['Const+GARCH', 'AR(1)+GARCH'],\n",
    "    'AIC': [res_const.aic, res_ar1.aic],\n",
    "    'BIC': [res_const.bic, res_ar1.bic],\n",
    "    'LB_resid_pval_lag10': [\n",
    "        lb_const_resid['lb_pvalue'].iloc[-1],\n",
    "        lb_ar1_resid['lb_pvalue'].iloc[-1]\n",
    "    ],\n",
    "    'LB_resid2_pval_lag10': [\n",
    "        lb_const_sq['lb_pvalue'].iloc[-1],\n",
    "        lb_ar1_sq['lb_pvalue'].iloc[-1]\n",
    "    ]\n",
    "})\n",
    "print(summary_df)\n",
    "```\n",
    "\n",
    "上のような表が得られます。\n",
    "実際に実行すると、例えば「こんな感じ」の結果になることが多いです（数値はイメージ）：\n",
    "\n",
    "```text\n",
    "          Model        AIC        BIC  LB_resid_pval_lag10  LB_resid2_pval_lag10\n",
    "0  Const+GARCH  1234.50    1260.10          0.18                  0.42\n",
    "1  AR(1)+GARCH  1233.90    1265.80          0.20                  0.40\n",
    "```\n",
    "\n",
    "典型的な S&P500 日次リターンだと：\n",
    "\n",
    "* AR(1) の係数 (\\varphi_1) は **かなり小さくて非有意** なことが多い\n",
    "* AIC は少し良くなることもあるが、BIC（ペナルティが強い）は逆に悪くなることもある\n",
    "* Ljung-Box の p値は、どちらのモデルでも十分大きくて「残差自己相関なし」と判定できることが多い\n",
    "\n",
    "→ **結論:**\n",
    "「このデータでは、わざわざ mean='AR' にしても大きな改善はなさそう。mean='Constant' でも十分。」\n",
    "という判断になるケースが多いです。\n",
    "\n",
    "逆に、**1時間足の為替データ** などでは：\n",
    "\n",
    "* AR(1) が有意に負になって「直近の動きが反転しやすい」\n",
    "* Ljung-Box も AR を入れた方がきれいに自己相関が消える\n",
    "\n",
    "といったことがあり、その場合は\n",
    "\n",
    "> AR(1)-GARCH の方が「平均のパターン」をきちんと説明してる\n",
    "\n",
    "と判断できます。\n",
    "\n",
    "---\n",
    "\n",
    "## 5. 何を見てモデルを選ぶか（実務的な判断軸）\n",
    "\n",
    "ざっくり言うと、\n",
    "\n",
    "1. **AR係数の有意性**\n",
    "\n",
    "   * `sp500_returns[1]` の P>|t| が 0.05 未満か？\n",
    "   * 大きくて有意 → AR を入れる意味がある\n",
    "   * 小さい・非有意 → 無理に入れなくてもよい\n",
    "\n",
    "2. **情報量基準（AIC/BIC）**\n",
    "\n",
    "   * AIC: 精度重視寄り（パラメータ数への罰則は弱め）\n",
    "   * BIC: シンプルさ重視寄り（パラメータ数への罰則が強い）\n",
    "   * 両方とも AR モデルの方が明確に小さい → AR を採用\n",
    "   * ほとんど差がない or BIC が悪化 → シンプルな constant でもOK\n",
    "\n",
    "3. **Ljung-Box の p値**\n",
    "\n",
    "   * **標準化残差** の p値（自己相関）\n",
    "\n",
    "     * AR を入れたことで p値が上がって「0.05超え」になった → 改善\n",
    "   * **標準化残差²** の p値（残りの ARCH 効果）\n",
    "\n",
    "     * ここは GARCH 部分の善し悪しなので、mean='AR' にしても大きくは変わらないことも多い\n",
    "\n",
    "---\n",
    "\n",
    "## まとめ\n",
    "\n",
    "* **今回の比較コード**でやっていること：\n",
    "\n",
    "  1. 同じリターン系列に対して\n",
    "  2. Constant+GARCH と AR(1)+GARCH を両方フィットし\n",
    "  3. AIC/BIC と Ljung-Box、AR係数の有意性で比較している\n",
    "\n",
    "* **理解してほしいポイント**：\n",
    "\n",
    "  * 「平均部分のモデル化」と「ボラティリティのモデル化」は役割が違う\n",
    "  * mean='AR' にするのは、「平均にまだ予測可能な構造が残っている」ときだけでよい\n",
    "  * S&P500 の日次リターンのような典型的な金融データでは、\n",
    "    **mean='Constant' で十分なことも多い**（効率的市場仮説っぽい世界）\n",
    "\n",
    "もしよければ、次は：\n",
    "\n",
    "* 1時間足のFX（例：`'USDJPY=X'`）か、先物データで同じ比較をしてみて\n",
    "  「どのデータだと AR が効いて、どのデータだと効かないか」を一緒に整理する\n",
    "\n",
    "みたいなステップもやってみましょうか？\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242db81b-3458-4f5d-9ff2-b3b712fa5da4",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "# dist を 'StudentsT' に変えて「ファットテール対応 GARCH」を試す\n",
    "\n",
    "dist を `'StudentsT'` に変えると、\n",
    "\n",
    "> 「**分散は GARCH で時変だけど、ショックの分布は正規ではなく“尻の重い t 分布”**」\n",
    "\n",
    "というモデルになります。\n",
    "金融リターンのように**ジャンプや極端値が多いデータ**では、かなり実務的に重要な選択肢です。\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 正規分布 vs t分布（StudentsT）の考え方\n",
    "\n",
    "GARCH モデルでは\n",
    "\n",
    "$$\n",
    "\\epsilon_t = \\sigma_t z_t\n",
    "$$\n",
    "\n",
    "の **(z_t) の分布**をどう仮定するか、が `dist` です。\n",
    "\n",
    "* `dist='Normal'`\n",
    "  → $(z_t \\sim N(0,1))$（標準正規）\n",
    "\n",
    "* `dist='StudentsT'`\n",
    "  → $(z_t \\sim t_\\nu)$（自由度 $(\\nu)$ の t 分布）\n",
    "\n",
    "t分布は\n",
    "\n",
    "* 真ん中は正規分布に似ているけど\n",
    "* **裾が太い（fat-tail）**\n",
    "\n",
    "  * 大きな値（= 大きなショック）の確率が正規より高い\n",
    "\n",
    "ので、\n",
    "\n",
    "> 「大暴落・急騰のような極端なリターンが、正規で想定するよりずっとよく起こる」\n",
    "\n",
    "という金融の現実を反映しやすくなります。\n",
    "\n",
    "`arch_model(..., dist='StudentsT')` にすると、\n",
    "\n",
    "* 推定パラメータに `nu`（自由度） が増えます\n",
    "* `nu` が小さいほど“裾が太い”\n",
    "\n",
    "  * `nu ≈ 30` 以上 → ほぼ正規に近い\n",
    "  * `nu ≈ 5` 〜 10 → かなり fat tail\n",
    "  * `nu ≤ 2` だと理論上分散が無限になるので、通常はもっと大きい値になります\n",
    "\n",
    "---\n",
    "\n",
    "## 2. コード例：正規 vs t分布 の GARCH(1,1) を比較\n",
    "\n",
    "### 2-1. 共通の前処理（S&P500 日次リターン）\n",
    "\n",
    "前と同じですが、比較のために一度まとめます。\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データ取得\n",
    "data = yf.download('^GSPC', start='2010-01-01', end='2023-12-31')\n",
    "\n",
    "# 日次リターン（%単位）\n",
    "returns = 100 * data['Adj Close'].pct_change().dropna()\n",
    "returns.name = 'sp500_returns'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2-2. モデル1：Normal-GARCH(1,1)\n",
    "\n",
    "まずは基準となる「正規誤差の GARCH(1,1)」。\n",
    "\n",
    "```python\n",
    "# === Normal 誤差の GARCH(1,1) ===\n",
    "am_norm = arch_model(\n",
    "    returns,\n",
    "    mean='Constant',\n",
    "    vol='Garch',\n",
    "    p=1, q=1,\n",
    "    dist='Normal'   # ★ここが Normal\n",
    ")\n",
    "res_norm = am_norm.fit(update_freq=5)\n",
    "print(res_norm.summary())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2-3. モデル2：StudentsT-GARCH(1,1)\n",
    "\n",
    "次に `dist='StudentsT'` に変えたモデル。\n",
    "\n",
    "```python\n",
    "# === t分布誤差の GARCH(1,1) ===\n",
    "am_t = arch_model(\n",
    "    returns,\n",
    "    mean='Constant',\n",
    "    vol='Garch',\n",
    "    p=1, q=1,\n",
    "    dist='StudentsT'   # ★ここだけ変更\n",
    ")\n",
    "res_t = am_t.fit(update_freq=5)\n",
    "print(res_t.summary())\n",
    "```\n",
    "\n",
    "`res_t.summary()` の Mean / Volatility に加えて、下の方に例えばこんな行が出ます（イメージです）:\n",
    "\n",
    "```text\n",
    "Distribution: StudentsT\n",
    "...\n",
    "nu      7.5    1.2   6.2   0.000  [5.2, 10.0]\n",
    "```\n",
    "\n",
    "* ここで `nu` が自由度\n",
    "* p値が 0.05 よりかなり小さければ\n",
    "  → 「正規ではなく t分布を使うべきだ」という統計的な根拠になる\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Normal vs t分布 の診断比較\n",
    "\n",
    "### 3-1. AIC/BIC と Ljung-Box\n",
    "\n",
    "2モデルを横並びで比較してみましょう。\n",
    "\n",
    "```python\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "def diag(res, name):\n",
    "    std_resid = res.std_resid.dropna()\n",
    "    lb_resid = acorr_ljungbox(std_resid, lags=[10], return_df=True)\n",
    "    lb_sq    = acorr_ljungbox(std_resid**2, lags=[10], return_df=True)\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'AIC': res.aic,\n",
    "        'BIC': res.bic,\n",
    "        'LB_resid_pval_lag10': lb_resid['lb_pvalue'].iloc[-1],\n",
    "        'LB_resid2_pval_lag10': lb_sq['lb_pvalue'].iloc[-1],\n",
    "    }\n",
    "\n",
    "diag_norm = diag(res_norm, 'Normal-GARCH(1,1)')\n",
    "diag_t    = diag(res_t,    't-GARCH(1,1)')\n",
    "\n",
    "summary_df = pd.DataFrame([diag_norm, diag_t])\n",
    "print(summary_df)\n",
    "```\n",
    "\n",
    "典型的な金融データでは、よくこんな傾向になります（あくまで例）：\n",
    "\n",
    "```text\n",
    "              Model        AIC        BIC  LB_resid_pval_lag10  LB_resid2_pval_lag10\n",
    "0  Normal-GARCH(1,1)   1234.5    1256.8          0.20                  0.03\n",
    "1  t-GARCH(1,1)        1225.0    1251.0          0.22                  0.15\n",
    "```\n",
    "\n",
    "この場合の読み方：\n",
    "\n",
    "* **AIC/BIC が小さい方がよい**\n",
    "  → `t-GARCH` の方がよい（両方とも小さい）\n",
    "* **LB_resid2_pval_lag10**\n",
    "\n",
    "  * Normal-GARCH: 0.03 → まだ残差²に自己相関（ARCH効果）が残っているかも\n",
    "  * t-GARCH: 0.15 → 0.05を超えていて OK\n",
    "\n",
    "こうなっていれば、\n",
    "\n",
    "> 「このデータでは、正規よりも t分布を使った方が GARCH モデルのあてはまりが良い」\n",
    "\n",
    "と判断しやすくなります。\n",
    "\n",
    "---\n",
    "\n",
    "## 4. 「fat-tail 対応 GARCH」をどう理解すればいいか\n",
    "\n",
    "### 4-1. 何が変わるのか？\n",
    "\n",
    "* **分散の推定（σ_t²）** 自体は、Normal と t で大きく変わらないことも多いです\n",
    "  → GARCH 部分は「時間的なボラティリティの構造」を見ているから\n",
    "* 一方で、**極端なリターンの扱い**が変わります：\n",
    "\n",
    "  * Normal-GARCH だと、大きな外れ値を「異常なデータ」として過剰に影響させてしまうことも\n",
    "  * t-GARCH だと、もともと裾が太いので\n",
    "\n",
    "    * 「極端値がそこそこ起こりやすい世界」を前提に推定\n",
    "    * ⇒ **パラメータ推定がロバスト**になりやすい\n",
    "\n",
    "### 4-2. 実務的なメリット\n",
    "\n",
    "* オプション価格や VaR を計算するとき：\n",
    "\n",
    "  * t-GARCH の方が「暴落時のリスク」を大きめに見積もることが多い\n",
    "  * リスク管理の観点では、安全側に倒したいときに好まれる\n",
    "* モデル診断上も\n",
    "\n",
    "  * Normal-GARCH では標準化残差の尾部にまだ大きな歪み・尖度が残る\n",
    "  * t-GARCH では残差分布がだいぶ「きれい」になることが多い\n",
    "\n",
    "---\n",
    "\n",
    "## 5. さらに一歩：標準化残差のヒストグラムと Q–Q プロット\n",
    "\n",
    "Normal と t の違いを **見た目で理解**するために、標準化残差をプロットしてみると良いです。\n",
    "\n",
    "```python\n",
    "import scipy.stats as st\n",
    "\n",
    "# 標準化残差\n",
    "std_resid_norm = res_norm.std_resid.dropna()\n",
    "std_resid_t    = res_t.std_resid.dropna()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# (1) Normal-GARCH の残差ヒストグラム + 正規密度\n",
    "ax = axes[0, 0]\n",
    "std_resid_norm.hist(bins=50, density=True, alpha=0.6, ax=ax)\n",
    "x = np.linspace(std_resid_norm.min(), std_resid_norm.max(), 200)\n",
    "ax.plot(x, st.norm.pdf(x), 'r-', label='N(0,1)')\n",
    "ax.set_title('Normal-GARCH std_resid (hist)')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# (2) t-GARCH の残差ヒストグラム + 正規密度\n",
    "ax = axes[0, 1]\n",
    "std_resid_t.hist(bins=50, density=True, alpha=0.6, ax=ax)\n",
    "x = np.linspace(std_resid_t.min(), std_resid_t.max(), 200)\n",
    "ax.plot(x, st.norm.pdf(x), 'r-', label='N(0,1)')\n",
    "ax.set_title('t-GARCH std_resid (hist)')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# (3) Normal-GARCH の Q-Q プロット\n",
    "ax = axes[1, 0]\n",
    "st.probplot(std_resid_norm, dist=\"norm\", plot=ax)\n",
    "ax.set_title('Normal-GARCH Q-Q plot')\n",
    "\n",
    "# (4) t-GARCH の Q-Q プロット\n",
    "ax = axes[1, 1]\n",
    "st.probplot(std_resid_t, dist=\"norm\", plot=ax)\n",
    "ax.set_title('t-GARCH Q-Q plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "* Normal-GARCH の Q–Q プロットでは、両端（尾部）が直線から大きく外れやすい\n",
    "* t-GARCH の方が、尾部の外れ具合が少しマシ（＝正規により近づく）になるケースが多い\n",
    "\n",
    "→ これを見ると、「t分布でフィットした方が、残差はだいぶ“正規に近い形”にまで処理されているな」という感覚がつかみやすいです。\n",
    "\n",
    "---\n",
    "\n",
    "## 6. まとめ：`dist='StudentsT'` を使うときの判断フロー\n",
    "\n",
    "1. まずは `dist='Normal'` で GARCH をフィット\n",
    "2. 標準化残差の\n",
    "\n",
    "   * ヒストグラム\n",
    "   * Q–Q プロット\n",
    "   * 歪度・尖度\n",
    "   * Ljung-Box（残差²）\n",
    "     を見て、「まだ尾部がおかしい／ARCH効果残ってそう」と感じたら\n",
    "3. `dist='StudentsT'` に変えて再推定\n",
    "4. AIC/BIC・残差診断・自由度 `nu` の有意性をチェック\n",
    "\n",
    "   * AIC/BIC↓\n",
    "   * `nu` の p値↓\n",
    "   * 残差²の Ljung-Box の p値↑\n",
    "     なら **t-GARCH 採用の理由がかなり強い**\n",
    "\n",
    "---\n",
    "\n",
    "ここまで押さえられると、\n",
    "\n",
    "* 「平均：Constant vs AR」\n",
    "* 「分布：Normal vs StudentsT」\n",
    "* 「分散：GARCH の次数を変える」\n",
    "\n",
    "といった**3つのレバーを自分で組み合わせて設計・診断**できるようになるので、かなり “中級 GARCH 使い” のレベルです。\n",
    "\n",
    "次の一歩としては、\n",
    "\n",
    "* `dist='StudentsT'` ＋ `mean='AR'` を一緒にした AR-GARCH-t\n",
    "* 非対称モデル（`vol='Garch'` → GJR-GARCH / EGARCH に変える）\n",
    "\n",
    "あたりをやると、実務のモデルにかなり近づきます。\n",
    "興味があれば、GJR-GARCH か EGARCH のどちらかを、今回と同じスタイルで一緒にやってみましょうか？\n",
    "\n",
    "<br>\n",
    "\n",
    "## 非対称モデルについて\n",
    "\n",
    "\n",
    "いいところに来ました！\n",
    "ここを押さえると「GARCHをわかってる人」感が一気に出ます 😊\n",
    "\n",
    "---\n",
    "\n",
    "## 0. なぜ「非対称モデル」が必要か？\n",
    "\n",
    "まず、ふつうの GARCH(1,1) では、\n",
    "\n",
    "$$\n",
    "\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2\n",
    "$$\n",
    "\n",
    "という形で、**ショックの大きさ（$(\\epsilon_{t-1}^2)$）だけ**を見ています。\n",
    "\n",
    "* 昨日 +5% 上昇 → $(\\epsilon_{t-1}^2)$ 大\n",
    "* 昨日 -5% 下落 → $(\\epsilon_{t-1}^2)$ 大\n",
    "\n",
    "どちらも **同じだけ** 将来ボラティリティを上げる、と仮定しているわけです。\n",
    "\n",
    "でも現実の株式市場では、\n",
    "\n",
    "> 同じ 5% でも「下落」の方が、その後のボラティリティを大きく上げる\n",
    "\n",
    "という **レバレッジ効果（asymmetric volatility / leverage effect）** がよく観測されます。\n",
    "\n",
    "この「**マイナスのショックの方が効きが強い**」をモデル化するのが、GJR-GARCH や EGARCH といった **非対称 GARCH** です。\n",
    "\n",
    "---\n",
    "\n",
    "## 1. GJR-GARCH（しきい値付き GARCH）\n",
    "\n",
    "### 1.1 数式イメージ\n",
    "\n",
    "代表的なのが GJR-GARCH(1,1,1)：\n",
    "\n",
    "$$\n",
    "\\sigma_t^2\n",
    "= \\omega + \\alpha \\epsilon_{t-1}^2 + \\gamma \\epsilon_{t-1}^2 I_{{\\epsilon_{t-1}<0}} + \\beta \\sigma_{t-1}^2\n",
    "$$\n",
    "\n",
    "- $(I_{{\\epsilon_{t-1}<0}})$ は「前期のショックがマイナスなら 1、そうでなければ 0」のダミー\n",
    "- $(\\gamma)$ が **レバレッジ効果の強さ**\n",
    "\n",
    "  * $(\\gamma > 0)$ なら「マイナスのショックの方が、ボラティリティをより強く押し上げる」\n",
    "\n",
    "プラスのショック（$(\\epsilon_{t-1}>0)$）のとき：\n",
    "$$\n",
    "\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2\n",
    "$$\n",
    "\n",
    "マイナスのショック（$(\\epsilon_{t-1}<0)$）のとき：\n",
    "$$\n",
    "\\sigma_t^2 = \\omega + (\\alpha + \\gamma)\\epsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2\n",
    "$$\n",
    "\n",
    "→ **下落時には係数が $(\\alpha + \\gamma)$ に増える**ので、「悪材料ほどボラティリティを高める」モデルになります。\n",
    "\n",
    "### 1.2 Python（arch）での実装：`o=1` を付ける\n",
    "\n",
    "`arch` ライブラリでは、\n",
    "\n",
    "* `vol='GARCH'`\n",
    "* `p`：GARCH ラグ数\n",
    "* `q`：ARCH ラグ数\n",
    "* `o`：**非対称（しきい値）ラグ数**\n",
    "\n",
    "を指定することで **GJR-GARCH** を実装できます。\n",
    "\n",
    "#### 前処理（共通）\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データ取得\n",
    "data = yf.download('^GSPC', start='2010-01-01', end='2023-12-31')\n",
    "\n",
    "# 日次リターン（%単位）\n",
    "returns = 100 * data['Adj Close'].pct_change().dropna()\n",
    "returns.name = 'sp500_returns'\n",
    "```\n",
    "\n",
    "#### GJR-GARCH(1,1,1) + t分布 誤差\n",
    "\n",
    "```python\n",
    "# GJR-GARCH(1,1,1) モデル\n",
    "# p=1: GARCH項, q=1: ARCH項, o=1: 非対称(負のショック用)項\n",
    "gjr = arch_model(\n",
    "    returns,\n",
    "    mean='Constant',\n",
    "    vol='GARCH',   # GARCH プロセス\n",
    "    p=1,\n",
    "    o=1,           # ★ここが GJR-GARCH のポイント\n",
    "    q=1,\n",
    "    dist='StudentsT'  # ファットテール対応\n",
    ")\n",
    "res_gjr = gjr.fit(update_freq=5)\n",
    "print(res_gjr.summary())\n",
    "```\n",
    "\n",
    "サマリーの Volatility 部分に、例えばこんな項目が出てきます（イメージ）：\n",
    "\n",
    "* `omega`\n",
    "* `alpha[1]`\n",
    "* `gamma[1]`  ← これが (\\gamma)（レバレッジ効果）\n",
    "* `beta[1]`\n",
    "\n",
    "見るべきポイント：\n",
    "\n",
    "* `gamma[1]` の係数が\n",
    "\n",
    "  * 正か？（マイナスのショックでボラティリティがより増える）\n",
    "  * P>|z| が 0.05 より十分小さいか？（統計的に有意か？）\n",
    "* `alpha[1] + gamma[1] + beta[1]` が 1 に近いか？\n",
    "\n",
    "  * GARCH と同様、ボラティリティ持続性の指標\n",
    "\n",
    "---\n",
    "\n",
    "## 2. EGARCH（Exponential GARCH）\n",
    "\n",
    "### 2.1 特徴と数式イメージ\n",
    "\n",
    "EGARCH(1,1) は、**分散ではなく「log 分散」を直接モデル化**します。\n",
    "\n",
    "典型的な EGARCH(1,1) の形：\n",
    "\n",
    "$$\n",
    "\\log \\sigma_t^2\n",
    "= \\omega + \\beta \\log \\sigma_{t-1}^2 +  \\alpha \\left( |z_{t-1}| - E|z_{t-1}| \\right) + \\gamma z_{t-1}\n",
    "$$\n",
    "\n",
    "\n",
    "- $(z_{t-1} = \\epsilon_{t-1} / \\sigma_{t-1})$（標準化残差）\n",
    "- $(|z_{t-1}|)$ の項 … **ショックの絶対値**（大きさ）への反応\n",
    "- $(z_{t-1})$ の項 … **ショックの符号（正/負）**への反応（非対称性）\n",
    "\n",
    "  * $(\\gamma < 0)$ だと、負のショック（$(z_{t-1}<0)$）のとき、対数分散がより大きく増える\n",
    "\n",
    "EGARCH の利点： \n",
    "\n",
    "1. **log を取っているので $(\\sigma_t^2>0)$ を自然に保証**（パラメータに非負制約をかけなくてよい）\n",
    "2. 非対称成分が「きれいな形」で入る（符号と大きさを分けて扱える）\n",
    "\n",
    "### 2.2 Python（arch）での実装：`vol='EGARCH'`\n",
    "\n",
    "`arch_model` で `vol='EGARCH'` を指定すれば EGARCH が使えます。\n",
    "\n",
    "```python\n",
    "# EGARCH(1,1) モデル（非対称ショック付き）\n",
    "egarch = arch_model(\n",
    "    returns,\n",
    "    mean='Constant',\n",
    "    vol='EGARCH',\n",
    "    p=1,  # GARCH ラグ\n",
    "    o=1,  # 非対称（レバレッジ）項のラグ数\n",
    "    q=1,  # ARCH ラグ\n",
    "    dist='StudentsT'\n",
    ")\n",
    "res_egarch = egarch.fit(update_freq=5)\n",
    "print(res_egarch.summary())\n",
    "```\n",
    "\n",
    "サマリーでは、Volatility のところに\n",
    "\n",
    "* `omega`\n",
    "* `alpha[1]`\n",
    "* `gamma[1]`（レバレッジ効果）\n",
    "* `beta[1]`\n",
    "\n",
    "などが表示されます。\n",
    "\n",
    "解釈の仕方：\n",
    "\n",
    "* `gamma[1]` が負で有意 →\n",
    "  「マイナスの標準化ショック（悪材料）のとき、log σ² がより伸びる」\n",
    "  → 負のショックの方が将来ボラティリティを強く押し上げる（レバレッジ効果）\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 対称 GARCH vs 非対称 GJR / EGARCH の比較コード\n",
    "\n",
    "「どれが良さそうか」を見るために、AIC/BIC と Ljung-Box を並べるとわかりやすいです。\n",
    "\n",
    "```python\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "def diag(res, name):\n",
    "    std_resid = res.std_resid.dropna()\n",
    "    lb_resid = acorr_ljungbox(std_resid, lags=[10], return_df=True)\n",
    "    lb_sq    = acorr_ljungbox(std_resid**2, lags=[10], return_df=True)\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'AIC': res.aic,\n",
    "        'BIC': res.bic,\n",
    "        'LB_resid_pval_lag10': lb_resid['lb_pvalue'].iloc[-1],\n",
    "        'LB_resid2_pval_lag10': lb_sq['lb_pvalue'].iloc[-1],\n",
    "    }\n",
    "\n",
    "# 1. 対称 GARCH(1,1)\n",
    "garch = arch_model(returns, mean='Constant', vol='GARCH',\n",
    "                   p=1, q=1, dist='StudentsT')\n",
    "res_garch = garch.fit(disp='off')\n",
    "\n",
    "# 2. GJR-GARCH(1,1,1)\n",
    "gjr = arch_model(returns, mean='Constant', vol='GARCH',\n",
    "                 p=1, o=1, q=1, dist='StudentsT')\n",
    "res_gjr = gjr.fit(disp='off')\n",
    "\n",
    "# 3. EGARCH(1,1)\n",
    "egarch = arch_model(returns, mean='Constant', vol='EGARCH',\n",
    "                    p=1, o=1, q=1, dist='StudentsT')\n",
    "res_egarch = egarch.fit(disp='off')\n",
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    diag(res_garch, 'GARCH(1,1)'),\n",
    "    diag(res_gjr,   'GJR-GARCH(1,1,1)'),\n",
    "    diag(res_egarch,'EGARCH(1,1)')\n",
    "])\n",
    "print(summary_df)\n",
    "```\n",
    "\n",
    "よくあるパターン（イメージ）：\n",
    "\n",
    "```text\n",
    "             Model        AIC        BIC  LB_resid_pval_lag10  LB_resid2_pval_lag10\n",
    "0        GARCH(1,1)  1234.5    1256.8            0.20                   0.04\n",
    "1  GJR-GARCH(1,1,1)  1228.0    1256.0            0.25                   0.18\n",
    "2       EGARCH(1,1)  1227.5    1255.5            0.26                   0.20\n",
    "```\n",
    "\n",
    "こんな感じなら：\n",
    "\n",
    "* AIC/BIC：EGARCH, GJR-GARCH の方が小さい\n",
    "* 残差²の Ljung-Box：非対称モデルの方が p値が大きく、「残りの ARCH 効果」が減っている\n",
    "\n",
    "→ **非対称モデルの方が、このデータのボラティリティの振る舞いをうまく捉えている**\n",
    "と判断できます。\n",
    "\n",
    "---\n",
    "\n",
    "## 4. どういうデータで非対称モデルが効きやすいか？\n",
    "\n",
    "* 株式・株価指数・クレジットスプレッドなど\n",
    "\n",
    "  * 「悪材料が出ると一気に下落＆ボラ急騰」というレバレッジ効果が強い\n",
    "  * GJR-GARCH / EGARCH の `gamma` が有意になることが多い\n",
    "* 為替や商品先物など\n",
    "\n",
    "  * シリーズによっては「上も下も対称」なものもある → 対称 GARCH で十分なことも\n",
    "\n",
    "なので実務的には、\n",
    "\n",
    "1. まず **対称 GARCH(1,1)** でフィット\n",
    "2. 残差診断・ニュースインパクトの非対称性が気になれば\n",
    "3. GJR-GARCH, EGARCH を試して\n",
    "\n",
    "   * AIC/BIC\n",
    "   * Ljung-Box\n",
    "   * `gamma` の符号と有意性\n",
    "\n",
    "を見て、**非対称モデルを採用するか決める**、という流れが多いです。\n",
    "\n",
    "---\n",
    "\n",
    "もし次のステップとして余力があれば、\n",
    "\n",
    "* 同じデータで GJR-GARCH と EGARCH の `gamma` の符号・大きさ・有意性を比べる\n",
    "* `mean='AR'` も組み合わせて AR(1)-EGARCH, AR(1)-GJR-GARCH をフィットして AIC/BIC を比較する\n",
    "\n",
    "というところまでやると、「平均・分散・分布・非対称性」を全部コントロールできる状態になります 👍\n",
    "\n",
    "そこまでやってみたい場合は、「S&P500 で GJR と EGARCH を実際に比較する notebook っぽいコードを一式ください」と言ってくれれば、そこまでまとめてお渡しします。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb38ffae-6a6b-4bdc-8ded-c6b797835524",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "# 「平均・分散・分布・非対称性」を全部コントロールできる状態になるために、S&P500 で GJR と EGARCH を実際に比較する notebook っぽいコード\n",
    "\n",
    "ここまで来たら、もう「GARCH職人」ですね 😊\n",
    "S&P500 を題材にして、\n",
    "\n",
    "* **平均**：Constant vs AR(1)\n",
    "* **分散モデル**：対称 GARCH vs 非対称 GJR-GARCH / EGARCH\n",
    "* **分布**：Normal vs StudentsT（t分布）\n",
    "* **非対称性**：有り / なし\n",
    "\n",
    "を全部切り替えながら比較できる「ノートブック一式」を用意します。\n",
    "\n",
    "---\n",
    "\n",
    "## 全体像\n",
    "\n",
    "下のコードは、Jupyter でそのまま上から順に実行できる構成になっています：\n",
    "\n",
    "1. セットアップ & データ取得\n",
    "2. 共通ユーティリティ（`fit_and_diagnose` 関数）\n",
    "3. 4つのモデルをフィット\n",
    "\n",
    "   * M1: AR(1) + GARCH(1,1) + Normal\n",
    "   * M2: AR(1) + GARCH(1,1) + StudentsT\n",
    "   * M3: AR(1) + **GJR-GARCH(1,1,1)** + StudentsT\n",
    "   * M4: AR(1) + **EGARCH(1,1)** + StudentsT\n",
    "4. モデル比較テーブル（AIC/BIC, Ljung-Box, 自由度 `nu`, 非対称パラメータ `gamma`）\n",
    "5. 条件付きボラティリティの可視化\n",
    "\n",
    "---\n",
    "\n",
    "## 1. セットアップ & データ取得\n",
    "\n",
    "```python\n",
    "# ===========================\n",
    "# セットアップ & データ取得\n",
    "# ===========================\n",
    "# ※ 初回のみ:\n",
    "# !pip install arch yfinance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "\n",
    "plt.style.use(\"default\")  # お好みで\n",
    "\n",
    "# --- S&P 500 (^GSPC) の日次データ取得 ---\n",
    "data = yf.download('^GSPC', start='2010-01-01', end='2023-12-31')\n",
    "\n",
    "# --- 日次リターン（%単位） ---\n",
    "# pct_change() は 0.01 = 1% のような小さい値→これを 100倍して「%リターン」にするのが\n",
    "# GARCH 推定を安定させる実務上の定石の一つです。\n",
    "returns = 100 * data['Adj Close'].pct_change().dropna()\n",
    "returns.name = 'sp500_returns'\n",
    "\n",
    "# 確認用プロット（任意）\n",
    "returns.plot(figsize=(12, 4), title='S&P 500 Daily Returns (%)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 共通ユーティリティ関数\n",
    "\n",
    "1つの関数 `fit_and_diagnose` で、\n",
    "\n",
    "* モデル構造（mean / vol / p,o,q / dist）を指定\n",
    "* フィットして\n",
    "* * AIC / BIC\n",
    "  * Ljung-Box（残差 / 残差²）\n",
    "  * `nu`（StudentsT の自由度）\n",
    "  * 非対称パラメータ `gamma`\n",
    "* をまとめて返します。\n",
    "\n",
    "```python\n",
    "# ===========================\n",
    "# 共通ユーティリティ関数\n",
    "# ===========================\n",
    "from typing import Optional, Dict\n",
    "\n",
    "\n",
    "def fit_and_diagnose(\n",
    "    y: pd.Series,\n",
    "    model_name: str,\n",
    "    mean: str = \"AR\",      # \"Constant\" or \"AR\"\n",
    "    lags: int = 1,         # mean=\"AR\" のときの AR次数\n",
    "    vol: str = \"GARCH\",    # \"GARCH\" or \"EGARCH\"\n",
    "    p: int = 1,\n",
    "    o: int = 0,\n",
    "    q: int = 1,\n",
    "    dist: str = \"Normal\"   # \"Normal\" or \"StudentsT\"\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    指定した構造の GARCH 系モデルをフィットし、\n",
    "    結果オブジェクトと 診断指標をまとめて返すヘルパー。\n",
    "    \"\"\"\n",
    "    # --- モデル定義 ---\n",
    "    am = arch_model(\n",
    "        y,\n",
    "        mean=mean,\n",
    "        lags=lags if mean == \"AR\" else None,\n",
    "        vol=vol,\n",
    "        p=p,\n",
    "        o=o,\n",
    "        q=q,\n",
    "        dist=dist\n",
    "    )\n",
    "\n",
    "    # --- フィット ---\n",
    "    res = am.fit(disp=\"off\")  # ノイズを抑える\n",
    "\n",
    "    # --- 標準化残差 ---\n",
    "    std_resid = res.std_resid.dropna()\n",
    "\n",
    "    # --- Ljung-Box 検定（ラグ10まで） ---\n",
    "    lb_resid = acorr_ljungbox(std_resid, lags=[10], return_df=True)\n",
    "    lb_resid2 = acorr_ljungbox(std_resid**2, lags=[10], return_df=True)\n",
    "\n",
    "    # --- t分布の自由度（StudentsT の場合だけ） ---\n",
    "    nu = None\n",
    "    if dist.lower().startswith(\"student\"):\n",
    "        if \"nu\" in res.params.index:\n",
    "            nu = res.params[\"nu\"]\n",
    "\n",
    "    # --- 非対称性パラメータ（GJRやEGARCHの gamma） ---\n",
    "    gamma = None\n",
    "    # GJR-GARCH: vol=\"GARCH\", o>0 で gamma[1], gamma[2], ...\n",
    "    for param_name in res.params.index:\n",
    "        if param_name.lower().startswith(\"gamma\"):\n",
    "            gamma = res.params[param_name]\n",
    "            break\n",
    "\n",
    "    # --- 結果まとめ ---\n",
    "    info = {\n",
    "        \"model_name\": model_name,\n",
    "        \"result\": res,\n",
    "        \"AIC\": res.aic,\n",
    "        \"BIC\": res.bic,\n",
    "        \"LB_resid_pval_lag10\": lb_resid[\"lb_pvalue\"].iloc[-1],\n",
    "        \"LB_resid2_pval_lag10\": lb_resid2[\"lb_pvalue\"].iloc[-1],\n",
    "        \"nu\": nu,\n",
    "        \"gamma\": gamma,\n",
    "    }\n",
    "    return info\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 4つのモデルをフィットして比較\n",
    "\n",
    "### モデル設計\n",
    "\n",
    "* **M1**: AR(1) + GARCH(1,1) + Normal\n",
    "* **M2**: AR(1) + GARCH(1,1) + StudentsT\n",
    "* **M3**: AR(1) + GJR-GARCH(1,1,1) + StudentsT\n",
    "\n",
    "  * `vol=\"GARCH\", o=1` が GJR-GARCH（非対称 GARCH）\n",
    "* **M4**: AR(1) + EGARCH(1,1) + StudentsT\n",
    "\n",
    "  * `vol=\"EGARCH\", o=1` が非対称 EGARCH\n",
    "\n",
    "```python\n",
    "# ===========================\n",
    "# 4つのモデルをフィット\n",
    "# ===========================\n",
    "models = []\n",
    "\n",
    "# M1: AR(1) + GARCH(1,1) + Normal\n",
    "m1 = fit_and_diagnose(\n",
    "    returns,\n",
    "    model_name=\"M1: AR(1)-GARCH(1,1)-Normal\",\n",
    "    mean=\"AR\", lags=1,\n",
    "    vol=\"GARCH\", p=1, o=0, q=1,\n",
    "    dist=\"Normal\"\n",
    ")\n",
    "models.append(m1)\n",
    "\n",
    "# M2: AR(1) + GARCH(1,1) + StudentsT\n",
    "m2 = fit_and_diagnose(\n",
    "    returns,\n",
    "    model_name=\"M2: AR(1)-GARCH(1,1)-t\",\n",
    "    mean=\"AR\", lags=1,\n",
    "    vol=\"GARCH\", p=1, o=0, q=1,\n",
    "    dist=\"StudentsT\"\n",
    ")\n",
    "models.append(m2)\n",
    "\n",
    "# M3: AR(1) + GJR-GARCH(1,1,1) + StudentsT\n",
    "#     → 非対称項 o=1 を追加（負のショックへの反応を別パラメータで表現）\n",
    "m3 = fit_and_diagnose(\n",
    "    returns,\n",
    "    model_name=\"M3: AR(1)-GJR-GARCH(1,1,1)-t\",\n",
    "    mean=\"AR\", lags=1,\n",
    "    vol=\"GARCH\", p=1, o=1, q=1,\n",
    "    dist=\"StudentsT\"\n",
    ")\n",
    "models.append(m3)\n",
    "\n",
    "# M4: AR(1) + EGARCH(1,1) + StudentsT\n",
    "#     → vol='EGARCH', p=1, o=1, q=1 で非対称EGARCH\n",
    "m4 = fit_and_diagnose(\n",
    "    returns,\n",
    "    model_name=\"M4: AR(1)-EGARCH(1,1)-t\",\n",
    "    mean=\"AR\", lags=1,\n",
    "    vol=\"EGARCH\", p=1, o=1, q=1,\n",
    "    dist=\"StudentsT\"\n",
    ")\n",
    "models.append(m4)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. モデル比較テーブルの作成と解説\n",
    "\n",
    "### 4-1. 指標一覧表\n",
    "\n",
    "```python\n",
    "# ===========================\n",
    "# モデル比較テーブル\n",
    "# ===========================\n",
    "summary_df = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": m[\"model_name\"],\n",
    "        \"AIC\": m[\"AIC\"],\n",
    "        \"BIC\": m[\"BIC\"],\n",
    "        \"LB_resid_pval_lag10\": m[\"LB_resid_pval_lag10\"],\n",
    "        \"LB_resid2_pval_lag10\": m[\"LB_resid2_pval_lag10\"],\n",
    "        \"nu (if t)\": m[\"nu\"],\n",
    "        \"gamma (asymmetry)\": m[\"gamma\"],\n",
    "    }\n",
    "    for m in models\n",
    "])\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:.4f}\".format)\n",
    "summary_df\n",
    "```\n",
    "\n",
    "### 4-2. 表の読み方（口頭解説）\n",
    "\n",
    "このテーブルから、次のような視点でモデルを比べます：\n",
    "\n",
    "1. **AIC / BIC**\n",
    "\n",
    "   * 小さいほど「よい」モデル（データに対して当てはまりがよく、かつ過剰パラメータでない）\n",
    "   * M1 vs M2 → **t分布で改善しているか？**\n",
    "   * M2 vs M3 / M4 → **非対称モデルでさらに改善しているか？**\n",
    "\n",
    "2. **LB_resid_pval_lag10**（標準化残差の Ljung-Box）\n",
    "\n",
    "   * 0.05 より大きい → 残差に自己相関は残っていない（平均モデルはOK）\n",
    "\n",
    "3. **LB_resid2_pval_lag10**（標準化残差²の Ljung-Box）\n",
    "\n",
    "   * 0.05 より大きい → 残りの ARCH 効果はほぼない（分散モデルはOK）\n",
    "   * M1 では 0.05 未満だが、M2, M3, M4 で 0.05 を超える…などなら\n",
    "     → それだけ「うまくボラティリティを説明できている」モデル\n",
    "\n",
    "4. **nu (if t)**（自由度）\n",
    "\n",
    "   * t分布を使っているモデル（M2, M3, M4）でのみ値が入る\n",
    "   * 小さいほど fat-tail（厚い裾）\n",
    "   * `nu` の推定値と、その p値（`res.params` の summary で確認）も見る\n",
    "     → 正規分布からの乖離が有意かどうか\n",
    "\n",
    "5. **gamma (asymmetry)**（非対称パラメータ）\n",
    "\n",
    "   * M3（GJR-GARCH） & M4（EGARCH）でのみ値が入るはず\n",
    "   * 正負 & p値で解釈\n",
    "\n",
    "     * GJR-GARCH: `gamma > 0` かつ有意\n",
    "       → 負のショックのときの方がボラティリティがより増える\n",
    "     * EGARCH: 一般に `gamma < 0` が「負のショックでボラ増大」になるように定義されることが多い\n",
    "       → 公式の符号はモデルの実装に依存するので、ドキュメントや論文の符号慣習も参照（ただ、`gamma` の有意性と符号は「非対称性の存在」を示す）\n",
    "\n",
    "---\n",
    "\n",
    "## 5. 条件付きボラティリティの可視化\n",
    "\n",
    "最後に、いくつかのモデルで **条件付きボラティリティ $(\\sigma_t)$** を比較します。\n",
    "\n",
    "```python\n",
    "# ===========================\n",
    "# 条件付きボラティリティの比較プロット\n",
    "# ===========================\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# 実際のリターン\n",
    "returns.plot(ax=ax[0])\n",
    "ax[0].set_title(\"S&P 500 Daily Returns (%)\")\n",
    "ax[0].grid(True)\n",
    "\n",
    "# 各モデルの条件付きボラティリティ\n",
    "for m in models:\n",
    "    res = m[\"result\"]\n",
    "    vol = res.conditional_volatility  # σ_t（%リターンの標準偏差）\n",
    "    ax[1].plot(vol, label=m[\"model_name\"])\n",
    "\n",
    "ax[1].set_title(\"Conditional Volatility (σ_t) from Each Model\")\n",
    "ax[1].set_ylabel(\"Volatility (% per day)\")\n",
    "ax[1].grid(True)\n",
    "ax[1].legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### このグラフの見方\n",
    "\n",
    "* 上段：実際のリターン（大きく上下している期間 ≒ ボラが高い期間）\n",
    "* 下段：各モデルが推定した条件付きボラティリティの系列\n",
    "\n",
    "  * Normal-GARCH（M1）：暴落局面でのボラのピークがやや違うかも\n",
    "  * t-GARCH（M2）：極端値への耐性があり、推定が少し滑らかになることも\n",
    "  * GJR / EGARCH（M3, M4）：\n",
    "\n",
    "    * 特に「急落があった直後」にボラティリティがより強く立ち上がる傾向があれば、\n",
    "      → **負のショックへの非対称な反応**をうまく捉えている証拠\n",
    "\n",
    "---\n",
    "\n",
    "## 6. このノートで「何ができるようになるか」\n",
    "\n",
    "この一式で、次ができるようになります：\n",
    "\n",
    "1. **平均（mean）**\n",
    "\n",
    "   * `mean=\"Constant\"` / `\"AR\"` と `lags` を変えて\n",
    "     → リターンに自己相関があるか & それをどこまで説明するかをコントロール\n",
    "\n",
    "2. **分散モデル（volatility dynamics）**\n",
    "\n",
    "   * `vol=\"GARCH\"` vs `\"EGARCH\"`\n",
    "   * `p, q` を変えて\n",
    "     → ボラティリティクラスタリングの強さ、持続性の表現力をコントロール\n",
    "\n",
    "3. **分布（dist）**\n",
    "\n",
    "   * `dist=\"Normal\"` vs `\"StudentsT\"`\n",
    "     → 極端値・ジャンプの扱いをコントロール（fat-tail 対応）\n",
    "\n",
    "4. **非対称性（レバレッジ効果）**\n",
    "\n",
    "   * `o=0`（対称） vs `o=1`（非対称）\n",
    "   * `gamma` の符号・有意性を見る\n",
    "     → 「下落の方がボラを上げやすい」現象をモデルに入れる / 入れないをコントロール\n",
    "\n",
    "---\n",
    "\n",
    "## 7. 次のステップ案\n",
    "\n",
    "ここまで来ると、もうかなり中級以上です。\n",
    "もしさらに深めるなら：\n",
    "\n",
    "* **ニュースインパクトカーブ**（News Impact Curve）を描いて、\n",
    "\n",
    "  * 同じ大きさの +ショック / -ショック が (\\sigma_t^2) にどう影響するかを可視化\n",
    "* 1時間足の FX や先物データに同じコードを適用して、\n",
    "\n",
    "  * 「どの市場がより非対称なのか？」\n",
    "  * 「どの頻度で AR 成分が効くのか？」\n",
    "\n",
    "などを比較してみると、かなり実務的な感覚もついてきます。\n",
    "\n",
    "もし「ニュースインパクトカーブを描くコードも欲しい」ですとか、「FX データで同じ比較をしたい」といった要望があれば、そのパターンも notebook 風に一式用意します！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452b47d-66ae-40a6-b770-674ff15678c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stud_rag",
   "language": "python",
   "name": "stud_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
